{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentice Chef Case - (Carlos) Andres Restrepo Ayala - Hult MsBA 2021 Class\n",
    "# Prediction Model\n",
    "# Assumption: The data delivered by marketing team was collected and stored correctly\n",
    "\n",
    "\"\"\"\n",
    "    Docstring:\n",
    "    \n",
    "    A) Purpose: This code tests different classification models to predict \n",
    "    how well perform a cross selling promotion where subscribers receive\n",
    "    a half bottle of wine from a local California vineyard every Wednesday.\n",
    "    \n",
    "    The acceptance of the promotion is stored as a binary variable \n",
    "    'CROSS_SELL_SUCCESS' an tested using the models: Logistic Regression, \n",
    "    Classification Tree, KNN, Random Forest and GBM and used hyperparameter\n",
    "    tuning to improve the models. The models are measured based on the AUC \n",
    "    result of the test splited data after run the set of models.\n",
    "    \n",
    "    Some line of code with \"print\" sentences were turn into comments after \n",
    "    were used to check the correct function of the code as well as the hyperparameter\n",
    "    tuning cells. You can turn active those line to see intermediate results .\n",
    "   \n",
    "    B) Bugs or malfunction as the code expected.\n",
    "    No bugs are detected after runing the code.\n",
    "\"\"\"    \n",
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # also <from matplotlib import pyplot as plt>\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import statsmodels.formula.api as smf# linear regression (statsmodels)\n",
    "from sklearn.model_selection import train_test_split # train/test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "import statsmodels.formula.api as smf                # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "from sklearn.model_selection import RandomizedSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from sklearn.tree import DecisionTreeClassifier      # classification trees\n",
    "from sklearn.tree import export_graphviz             # exports graphics\n",
    "from six import StringIO           # saves objects in memory\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus   \n",
    "from sklearn.ensemble import RandomForestClassifier     # random forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier # gbm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time \n",
    "#Start timer\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# visual_cm\n",
    "########################################\n",
    "def visual_cm(true_y, pred_y, labels = None):\n",
    "    \"\"\"\n",
    "Creates a visualization of a confusion matrix.\n",
    "\n",
    "PARAMETERS\n",
    "----------\n",
    "true_y : true values for the response variable\n",
    "pred_y : predicted values for the response variable\n",
    "labels : , default None\n",
    "    \"\"\"\n",
    "    # visualizing the confusion matrix\n",
    "\n",
    "    # setting labels\n",
    "    lbls = labels\n",
    "    \n",
    "\n",
    "    # declaring a confusion matrix object\n",
    "    cm = confusion_matrix(y_true = true_y,\n",
    "                          y_pred = pred_y)\n",
    "\n",
    "\n",
    "    # heatmap\n",
    "    sns.heatmap(cm,\n",
    "                annot       = True,\n",
    "                xticklabels = lbls,\n",
    "                yticklabels = lbls,\n",
    "                cmap        = 'Blues',\n",
    "                fmt         = 'g')\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix of the Classifier')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial preparing the dataframe\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# reading the dataframe\n",
    "file ='./datasets/Apprentice_Chef_Dataset.xlsx'\n",
    "df_meals = pd.read_excel(io = file)\n",
    "\n",
    "# renaming LARGEST_ORDER_SIZE variable\n",
    "df_meals= df_meals.rename(columns = {'LARGEST_ORDER_SIZE': 'AVG_MEALSORDER_PER_CUSTOMER'})\n",
    "\n",
    "# droping categorical variables for linear modeling\n",
    "df_meals = df_meals.drop(['NAME', 'FIRST_NAME','FAMILY_NAME'],    # Temporary no include 'EMAIL' from list of droped\n",
    "                         axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering Email\n",
    "# This part of the code just can be run once\n",
    "\n",
    "# splitting emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in df_meals.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = df_meals.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = [ '0' , 'EMAIL_DOMAIN' ]\n",
    "\n",
    "\n",
    "# defining Emails Domain Groups\n",
    "professional_email_domains = ['@mmm.com', '@amex.com', '@apple.com',\n",
    "                              '@boeing.com', '@caterpillar.com', '@chevron.com',\n",
    "                             '@cisco.com', '@cocacola.com', '@disney.com',\n",
    "                             '@dupont.com', '@exxon.com', '@ge.org', \n",
    "                              '@goldmansacs.com', '@homedepot.com', '@ibm.com',\n",
    "                             '@intel.com', '@jnj.com', '@jpmorgan.com', \n",
    "                              '@mcdonalds.com', '@merck.com', '@microsoft.com',\n",
    "                             '@nike.com', '@pfizer.com', '@pg.com', \n",
    "                              '@travelers.com', '@unitedtech.com', \n",
    "                              '@verizon.com','@visa.com', '@walmart.com']\n",
    "\n",
    "personal_email_domains     = ['@gmail.com', '@yahoo.com', '@protonmail.com']\n",
    "\n",
    "junk_email_domains         = ['@me.com', '@aol.com', '@hotmail.com', \n",
    "                              '@live.com', '@msn.com', '@passport.com']\n",
    "\n",
    "# resetting placeholderlist\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in email_df['EMAIL_DOMAIN']:\n",
    "        if  '@' + domain in professional_email_domains:\n",
    "            placeholder_lst.append('PROFESSIONAL')\n",
    "        \n",
    "        elif '@' + domain in personal_email_domains:\n",
    "            placeholder_lst.append('PERSONAL')\n",
    "            \n",
    "        elif '@' + domain in junk_email_domains:\n",
    "            placeholder_lst.append('JUNK')\n",
    "            \n",
    "        else:\n",
    "            placeholder_lst.append('NEW_DOMAIN')\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "df_meals['DOMAIN_GROUP'] = pd.Series(placeholder_lst)\n",
    "\n",
    "# checking results\n",
    "df_meals['DOMAIN_GROUP'].value_counts()\n",
    "\n",
    "# one hot encoding \n",
    "one_hot_email_domain       = pd.get_dummies(df_meals['DOMAIN_GROUP'])\n",
    "\n",
    "# dropping categorical variables after they've been encoded\n",
    "df_meals = df_meals.drop('DOMAIN_GROUP', axis = 1)\n",
    "\n",
    "# joining codings together\n",
    "df_meals = df_meals.join([one_hot_email_domain])\n",
    "\n",
    "# removing original EMAIL variable\n",
    "df_meals = df_meals.drop(['EMAIL'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "# Recoding Explanatory variables using dummy variables\n",
    "\n",
    "# Dummy variables for recoding\n",
    "df_meals['WEEKLY_SUBSCRIPTION']  = 0\n",
    "df_meals['SAW_INSTRUCTIONS']     = 0\n",
    "df_meals['TOOK_MASTERCLASS']     = 0\n",
    "df_meals['DELIVERY_MIN_ONTIME']  = 0\n",
    "df_meals['TOOK_INSTRUCTIONS']    = 0\n",
    "df_meals['CANCEL_ORDERS']        = 0\n",
    "df_meals['AVR_ORDER_ABOVE_MEAN'] = 0\n",
    "df_meals['TOTAL_LOGINS']         = 0\n",
    "df_meals['REVENUE_PER_CUSTOMER'] = 0\n",
    "df_meals['REVENUE_PER_MEAL']     = 0\n",
    "df_meals['POSIBLE_WINE']         = 0\n",
    "\n",
    "# Iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in df_meals.iterrows():\n",
    "    \n",
    "    # WEEKLY_PLAN\n",
    "    if df_meals.loc[index, 'WEEKLY_PLAN'] > 0:\n",
    "        df_meals.loc[index, 'WEEKLY_SUBSCRIPTION'] = 1\n",
    "        \n",
    "    # AVG_PREP_VID_TIME\n",
    "    if df_meals.loc[index, 'AVG_PREP_VID_TIME'] > 0:\n",
    "        df_meals.loc[index, 'SAW_INSTRUCTIONS'] = 1\n",
    "    \n",
    "    # MASTER_CLASSES_ATTENDED\n",
    "    if df_meals.loc[index, 'MASTER_CLASSES_ATTENDED'] > 0:\n",
    "        df_meals.loc[index, 'TOOK_MASTERCLASS'] = 1\n",
    "        \n",
    "    # Delivery Always at least on time \n",
    "    if df_meals.loc[index, 'EARLY_DELIVERIES'] > 0 and \\\n",
    "        df_meals.loc[index, 'LATE_DELIVERIES'] == 0:\n",
    "            df_meals.loc[index, 'DELIVERY_MIN_ONTIME'] = 1\n",
    "    \n",
    "    # Instruction from video and masterclass  \n",
    "    if df_meals.loc[index, 'AVG_PREP_VID_TIME'] > 0 and \\\n",
    "        df_meals.loc[index, 'MASTER_CLASSES_ATTENDED'] > 0:\n",
    "            df_meals.loc[index, 'TOOK_INSTRUCTIONS'] = 1\n",
    "\n",
    "    \n",
    "    # Canceling orders\n",
    "    if df_meals.loc[index, 'CANCELLATIONS_BEFORE_NOON'] > 0 and \\\n",
    "        df_meals.loc[index, 'CANCELLATIONS_AFTER_NOON'] > 0:\n",
    "            df_meals.loc[index, 'CANCEL_ORDERS'] = 1\n",
    "\n",
    "    \n",
    "    # Average order more than 3 times\n",
    "    if df_meals.loc[index, 'AVG_MEALSORDER_PER_CUSTOMER'] > 3: \n",
    "            df_meals.loc[index, 'AVR_ORDER_ABOVE_MEAN'] = 1\n",
    "            \n",
    "    # Total logins using different devices\n",
    "    df_meals.loc[index, 'TOTAL_LOGINS'] = df_meals.loc[index, 'MOBILE_LOGINS'] + \\\n",
    "        df_meals.loc[index, 'PC_LOGINS']\n",
    "    \n",
    "    # Calculating revenue per customer\n",
    "    df_meals.loc[index, 'REVENUE_PER_CUSTOMER'] = df_meals.loc[index, 'REVENUE'] / \\\n",
    "        df_meals.loc[index, 'AVG_MEALSORDER_PER_CUSTOMER']\n",
    "    \n",
    "    # Calculating revenue per meal\n",
    "    df_meals.loc[index, 'REVENUE_PER_MEAL'] = df_meals.loc[index, 'REVENUE'] / \\\n",
    "        df_meals.loc[index, 'TOTAL_MEALS_ORDERED']\n",
    "    \n",
    "    # Estimating order which possible included wine as Revene_per_meal above 30\n",
    "    # 30 = min price with wine plus max price of food per meal\n",
    "    if df_meals.loc[index , 'REVENUE_PER_MEAL'] > 30:\n",
    "        df_meals.loc[index, 'POSIBLE_WINE'] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuring engineering\n",
    "\n",
    "# recoding TOTAL_PHOTOS_VIEWED - counting the number of zeroes for \n",
    "photos_zeroes   = len(df_meals['TOTAL_PHOTOS_VIEWED'][df_meals['TOTAL_PHOTOS_VIEWED'] == 0]) # TOTAL PHOTOS\n",
    "\n",
    "# printing a table of the results\n",
    "#print(f\"\"\"\n",
    "#                 No\\t\\tYes\n",
    "#               ---------------------\n",
    "#Photos       | {photos_zeroes}\\t\\t{len(df_meals) - photos_zeroes}\n",
    "#\"\"\")\n",
    "\n",
    "# recogind the variable\n",
    "df_meals['PHOTOS_VIEWED']    = 0\n",
    "\n",
    "\n",
    "# Iterating over each original column to\n",
    "# change values in the new feature columns\n",
    "for index, value in df_meals.iterrows():\n",
    "    \n",
    "    # WEEKLY_PLAN\n",
    "    if df_meals.loc[index, 'TOTAL_PHOTOS_VIEWED'] > 0:\n",
    "        df_meals.loc[index, 'PHOTOS_VIEWED'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the dataframe\n",
    "\n",
    "# creating a copy of the dataframe\n",
    "df_meals_norm = pd.DataFrame(df_meals).copy()\n",
    "\n",
    "# creating the list of columns to normalize\n",
    "column_names_to_normalize = ['REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH',\n",
    "                            'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED',\n",
    "                            'AVG_TIME_PER_SITE_VISIT', 'CANCELLATIONS_BEFORE_NOON',\n",
    "                            'CANCELLATIONS_AFTER_NOON', 'PC_LOGINS', 'MOBILE_LOGINS',\n",
    "                            'WEEKLY_PLAN', 'EARLY_DELIVERIES', 'LATE_DELIVERIES',\n",
    "                            'AVG_PREP_VID_TIME', 'AVG_MEALSORDER_PER_CUSTOMER',\n",
    "                            'MASTER_CLASSES_ATTENDED', 'MEDIAN_MEAL_RATING',\n",
    "                            'AVG_CLICKS_PER_VISIT', 'TOTAL_PHOTOS_VIEWED',\n",
    "                            'TOTAL_LOGINS', 'REVENUE_PER_CUSTOMER', \n",
    "                            'REVENUE_PER_MEAL']\n",
    "\n",
    "# creating the object to normalize\n",
    "x = df_meals_norm[column_names_to_normalize].values\n",
    "\n",
    "# Instantiating the scales\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# fitting and transformind the variables\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# setting as dataframe\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = df_meals_norm.index)\n",
    "\n",
    "# saving the results in the copied dataframe\n",
    "df_meals_norm[column_names_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meals_norm\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "df_meals_norm = pd.DataFrame(df_meals_norm)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "df_meals_norm.to_excel('./datasets/classification_df_meals_norm.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for classification models using SciKit-learn with explanatory sets of variables\n",
    "\n",
    "# creating a dictionary to store candidate models\n",
    "\n",
    "candidate_dict = {\n",
    "\n",
    " # full model\n",
    " 'logit_full'   : ['REVENUE', 'TOTAL_MEALS_ORDERED', 'UNIQUE_MEALS_PURCH', \n",
    "                   'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED',\n",
    "                   'AVG_TIME_PER_SITE_VISIT', 'MOBILE_NUMBER',\n",
    "                   'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON',\n",
    "                   'TASTES_AND_PREFERENCES', 'PC_LOGINS', 'MOBILE_LOGINS',\n",
    "                   'WEEKLY_PLAN', 'EARLY_DELIVERIES', 'LATE_DELIVERIES',\n",
    "                   'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER', 'AVG_PREP_VID_TIME',\n",
    "                   'AVG_MEALSORDER_PER_CUSTOMER', 'MASTER_CLASSES_ATTENDED',\n",
    "                   'MEDIAN_MEAL_RATING', 'AVG_CLICKS_PER_VISIT',\n",
    "                   'TOTAL_PHOTOS_VIEWED', 'JUNK', 'PERSONAL', 'PROFESSIONAL',\n",
    "                   'WEEKLY_SUBSCRIPTION', 'SAW_INSTRUCTIONS', 'TOOK_MASTERCLASS',\n",
    "                   'DELIVERY_MIN_ONTIME', 'TOOK_INSTRUCTIONS', 'CANCEL_ORDERS',\n",
    "                   'AVR_ORDER_ABOVE_MEAN', 'TOTAL_LOGINS', 'REVENUE_PER_CUSTOMER',\n",
    "                   'REVENUE_PER_MEAL', 'POSIBLE_WINE', 'PHOTOS_VIEWED'],\n",
    " \n",
    "\n",
    "# significant variables after droping the transformed variables\n",
    " 'logit_sig_1'    : ['REVENUE', 'UNIQUE_MEALS_PURCH', \n",
    "                   'CONTACTS_W_CUSTOMER_SERVICE', 'PRODUCT_CATEGORIES_VIEWED',\n",
    "                   'AVG_TIME_PER_SITE_VISIT', 'MOBILE_NUMBER',\n",
    "                   'CANCELLATIONS_BEFORE_NOON', 'CANCELLATIONS_AFTER_NOON',\n",
    "                   'TASTES_AND_PREFERENCES', 'EARLY_DELIVERIES', \n",
    "                   'LATE_DELIVERIES', 'PACKAGE_LOCKER', 'REFRIGERATED_LOCKER',\n",
    "                   'MEDIAN_MEAL_RATING', 'AVG_CLICKS_PER_VISIT',\n",
    "                   'TOTAL_PHOTOS_VIEWED', 'JUNK', 'PERSONAL', 'PROFESSIONAL',\n",
    "                   'WEEKLY_SUBSCRIPTION', 'SAW_INSTRUCTIONS', 'TOOK_MASTERCLASS',\n",
    "                   'DELIVERY_MIN_ONTIME', 'TOOK_INSTRUCTIONS', \n",
    "                   'AVR_ORDER_ABOVE_MEAN', 'TOTAL_LOGINS', 'REVENUE_PER_CUSTOMER',\n",
    "                   'REVENUE_PER_MEAL', 'POSIBLE_WINE', 'PHOTOS_VIEWED'],\n",
    "    \n",
    "    \n",
    " # significant variables in the basic logistic regression\n",
    "'logit_sig_2'  : [ 'CONTACTS_W_CUSTOMER_SERVICE', 'MOBILE_NUMBER', \n",
    "                   'CANCELLATIONS_BEFORE_NOON', 'TASTES_AND_PREFERENCES',\n",
    "                   'JUNK', 'POSIBLE_WINE' ]\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split with the full model\n",
    "df_meals_norm_data   =  df_meals_norm.loc[ : , candidate_dict['logit_sig_1']]\n",
    "df_meals_norm_target =  df_meals_norm.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# this is the exact code we were using before\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            df_meals_norm_data,\n",
    "            df_meals_norm_target,\n",
    "            random_state = 219,\n",
    "            test_size    = 0.25,\n",
    "            stratify     = df_meals_norm_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg Training ACCURACY: 0.7238\n",
      "LogReg Testing  ACCURACY: 0.7269\n",
      "LogReg Train-Test Gap   : 0.0031\n",
      "[[ 53 103]\n",
      " [ 30 301]]\n",
      "\n",
      "True Negatives : 53\n",
      "False Positives: 103\n",
      "False Negatives: 30\n",
      "True Positives : 301\n",
      "\n",
      " AUC score: 0.6246\n"
     ]
    }
   ],
   "source": [
    "# First Logistic regression using SciKit\n",
    "\n",
    "# INSTANTIATING a logistic regression model\n",
    "logreg = LogisticRegression(solver = 'lbfgs',\n",
    "                            C = 1,\n",
    "                            random_state = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "logreg_fit = logreg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "logreg_pred = logreg_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('LogReg Training ACCURACY:', logreg_fit.score(x_train, y_train).round(4))\n",
    "print('LogReg Testing  ACCURACY:', logreg_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "# saving scoring data for future use\n",
    "logreg_train_score = logreg_fit.score(x_train, y_train).round(4) # accuracy\n",
    "logreg_test_score  = logreg_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# displaying and saving the gap between training and testing\n",
    "print('LogReg Train-Test Gap   :', abs(logreg_train_score - logreg_test_score).round(4))\n",
    "logreg_test_gap = abs(logreg_train_score - logreg_test_score).round(4)\n",
    "\n",
    "# Confusion matrix for fist logistic regression\n",
    "\n",
    "# creating a confusion matrix\n",
    "print(confusion_matrix(y_true = y_test,\n",
    "                       y_pred = logreg_pred))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "logreg_tn, \\\n",
    "logreg_fp, \\\n",
    "logreg_fn, \\\n",
    "logreg_tp = confusion_matrix(y_true = y_test, y_pred = logreg_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {logreg_tn}\n",
    "False Positives: {logreg_fp}\n",
    "False Negatives: {logreg_fn}\n",
    "True Positives : {logreg_tp}\n",
    "\"\"\")\n",
    "\n",
    "# Calculatin AUC\n",
    "\n",
    "# area under the roc curve (auc)\n",
    "print(f\"\"\" AUC score: {roc_auc_score(y_true  = y_test,\n",
    "                    y_score = logreg_pred).round(decimals = 4)}\"\"\")\n",
    "\n",
    "\n",
    "# saving AUC score for future use\n",
    "logreg_auc_score = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = logreg_pred).round(decimals = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning** for Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "# RandomizedSearchCV\n",
    "########################################\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "# C_space          = pd.np.arange(0.1, 10.0, 0.1)\n",
    "# warm_start_space = [True, False]\n",
    "# solver_space     = ['newton-cg', 'sag', 'lbfgs', 'liblinear', 'saga']\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "# param_grid = {'C'          : C_space,\n",
    "#               'warm_start' : warm_start_space,\n",
    "#               'solver'     : solver_space}\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "# lr_tuned = LogisticRegression(random_state = 219,\n",
    "#                               max_iter     = 1000)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "# lr_tuned_cv = RandomizedSearchCV(estimator           = lr_tuned,   # the model object\n",
    "#                                  param_distributions = param_grid, # parameters to tune\n",
    "#                                  cv                  = 3,          # how many folds in cross-validation\n",
    "#                                  n_iter              = 250,        # number of combinations of hyperparameters to try\n",
    "#                                  random_state        = 219,        # starting point for random sequence\n",
    "#                                  scoring = make_scorer(\n",
    "#                                            roc_auc_score,\n",
    "#                                            needs_threshold = False)) # scoring criteria (AUC)\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "# lr_tuned_cv.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", lr_tuned_cv.best_params_)\n",
    "# print(\"Tuned CV AUC      :\", lr_tuned_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of **Hyperparameter tuning** for Logistic Regression\n",
    "\n",
    "Tuned Parameters  : {'warm_start': False, 'solver': 'sag', 'C': 9.6}\\\n",
    "Tuned CV AUC      : 0.6314"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Tuned Training ACCURACY: 0.7313\n",
      "LR Tuned Testing  ACCURACY: 0.7372\n",
      "LR Tuned AUC Score        : 0.6389\n",
      "\n",
      "True Negatives : 57\n",
      "False Positives: 99\n",
      "False Negatives: 29\n",
      "True Positives : 302\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "lr_tuned = LogisticRegression(solver       = 'sag',\n",
    "                              C            = 9.6,\n",
    "                              warm_start   = False,\n",
    "                              random_state = 219)\n",
    "\n",
    "# FIT step is not needed\n",
    "# FITTING the training data\n",
    "lr_tuned_fit = lr_tuned.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "lr_tuned_pred = lr_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('LR Tuned Training ACCURACY:', lr_tuned.score(x_train, y_train).round(4))\n",
    "print('LR Tuned Testing  ACCURACY:', lr_tuned.score(x_test, y_test).round(4))\n",
    "print('LR Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = lr_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "lr_tuned_train_score = lr_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "lr_tuned_test_score  = lr_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "lr_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = lr_tuned_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "lr_tuned_tn, \\\n",
    "lr_tuned_fp, \\\n",
    "lr_tuned_fn, \\\n",
    "lr_tuned_tp = confusion_matrix(y_true = y_test, y_pred = lr_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {lr_tuned_tn}\n",
    "False Positives: {lr_tuned_fp}\n",
    "False Negatives: {lr_tuned_fn}\n",
    "True Positives : {lr_tuned_tp}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification tree** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Tree Training ACCURACY: 1.0\n",
      "Full Tree Testing ACCURACY : 0.5955\n",
      "Full Tree AUC Score: 0.5414\n",
      "\n",
      "True Negatives : 61\n",
      "False Positives: 95\n",
      "False Negatives: 102\n",
      "True Positives : 229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first classification tree\n",
    "\n",
    "# INSTANTIATING a classification tree object\n",
    "full_tree = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "full_tree_fit = full_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "full_tree_pred = full_tree_fit.predict(x_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Full Tree Training ACCURACY:', full_tree_fit.score(x_train,\n",
    "                                                     y_train).round(4))\n",
    "\n",
    "print('Full Tree Testing ACCURACY :', full_tree_fit.score(x_test,\n",
    "                                                     y_test).round(4))\n",
    "\n",
    "print('Full Tree AUC Score:', roc_auc_score(y_true  = y_test,\n",
    "                                            y_score = full_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "full_tree_train_score = full_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "full_tree_test_score  = full_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving AUC\n",
    "full_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                      y_score = full_tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "full_tree_tn, \\\n",
    "full_tree_fp, \\\n",
    "full_tree_fn, \\\n",
    "full_tree_tp = confusion_matrix(y_true = y_test, y_pred = full_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {full_tree_tn}\n",
    "False Positives: {full_tree_fp}\n",
    "False Negatives: {full_tree_fn}\n",
    "True Positives : {full_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pruned Tree**  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7642\n",
      "Testing  ACCURACY: 0.7023\n",
      "AUC Score        : 0.6217\n",
      "\n",
      "True Negatives : 62\n",
      "False Positives: 94\n",
      "False Negatives: 51\n",
      "True Positives : 280\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING a classification tree object\n",
    "pruned_tree = DecisionTreeClassifier(max_depth = 8,\n",
    "                                     min_samples_leaf = 16,\n",
    "                                     random_state = 219)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "pruned_tree_fit  = pruned_tree.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING on new data\n",
    "pruned_tree_pred = pruned_tree_fit.predict(x_test)\n",
    "\n",
    "# SCORING the model\n",
    "print('Training ACCURACY:', pruned_tree_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', pruned_tree_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = pruned_tree_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "pruned_tree_train_score = pruned_tree_fit.score(x_train, y_train).round(4) # accuracy\n",
    "pruned_tree_test_score  = pruned_tree_fit.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving auc score\n",
    "pruned_tree_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                        y_score = pruned_tree_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "pruned_tree_tn, \\\n",
    "pruned_tree_fp, \\\n",
    "pruned_tree_fn, \\\n",
    "pruned_tree_tp = confusion_matrix(y_true = y_test, y_pred = pruned_tree_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {pruned_tree_tn}\n",
    "False Positives: {pruned_tree_fp}\n",
    "False Negatives: {pruned_tree_fn}\n",
    "True Positives : {pruned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning** for Classification Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# criterion_space = ['gini', 'entropy']\n",
    "# splitter_space  = ['best', 'random']\n",
    "# depth_space     = pd.np.arange(1, 8, 1)\n",
    "# leaf_space      = pd.np.arange(1, 100, 1)\n",
    "\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'criterion'        : criterion_space,\n",
    "#               'splitter'         : splitter_space,\n",
    "#               'max_depth'        : depth_space,\n",
    "#               'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# tuned_tree = DecisionTreeClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # RandomizedSearchCV object\n",
    "# tuned_tree_cv = RandomizedSearchCV(estimator             = tuned_tree,\n",
    "#                                    param_distributions   = param_grid,\n",
    "#                                    cv                    = 3,\n",
    "#                                    n_iter                = 1000,\n",
    "#                                    random_state          = 219,\n",
    "#                                    scoring = make_scorer(roc_auc_score,\n",
    "#                                              needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# tuned_tree_cv.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of **Hyperparameter tuning** for Classification Tree:\n",
    "\n",
    "Tuned Parameters  : {'splitter': 'random', 'min_samples_leaf': 14, 'max_depth': 5, 'criterion': 'entropy'}\\\n",
    "Tuned Training AUC: 0.6265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7437\n",
      "Testing  ACCURACY: 0.7515\n",
      "AUC Score        : 0.6495\n",
      "\n",
      "True Negatives : 57\n",
      "False Positives: 99\n",
      "False Negatives: 22\n",
      "True Positives : 309\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned =  DecisionTreeClassifier(max_depth        = 5,\n",
    "                                     min_samples_leaf = 14,\n",
    "                                     splitter         = 'random',\n",
    "                                     criterion        = 'entropy',\n",
    "                                     random_state     = 219)\n",
    "\n",
    "# FIT step is not needed\n",
    "tree_tuned_fit  = tree_tuned.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "tree_tuned_train_score = tree_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "tree_tuned_test_score  = tree_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "tree_tuned_auc         = roc_auc_score(y_true  = y_test,\n",
    "                                     y_score = tree_tuned_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_tree_tn, \\\n",
    "tuned_tree_fp, \\\n",
    "tuned_tree_fn, \\\n",
    "tuned_tree_tp = confusion_matrix(y_true = y_test, y_pred = tree_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_tree_tn}\n",
    "False Positives: {tuned_tree_fp}\n",
    "False Negatives: {tuned_tree_fn}\n",
    "True Positives : {tuned_tree_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN** Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is: 19\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# optimal_neighbors\n",
    "########################################\n",
    "def optimal_neighbors(X_data,\n",
    "                      y_data,\n",
    "                      standardize = True,\n",
    "                      pct_test=0.25,\n",
    "                      seed=219,\n",
    "                      response_type='reg',\n",
    "                      max_neighbors=20,\n",
    "                      show_viz=True):\n",
    "    \"\"\"\n",
    "Exhaustively compute training and testing results for KNN across\n",
    "[1, max_neighbors]. Outputs the maximum test score and (by default) a\n",
    "visualization of the results.\n",
    "PARAMETERS\n",
    "----------\n",
    "X_data        : explanatory variable data\n",
    "y_data        : response variable\n",
    "standardize   : whether or not to standardize the X data, default True\n",
    "pct_test      : test size for training and validation from (0,1), default 0.25\n",
    "seed          : random seed to be used in algorithm, default 219\n",
    "response_type : type of neighbors algorithm to use, default 'reg'\n",
    "    Use 'reg' for regression (KNeighborsRegressor)\n",
    "    Use 'class' for classification (KNeighborsClassifier)\n",
    "max_neighbors : maximum number of neighbors in exhaustive search, default 20\n",
    "show_viz      : display or surpress k-neigbors visualization, default True\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "    if standardize == True:\n",
    "        # optionally standardizing X_data\n",
    "        scaler             = StandardScaler()\n",
    "        scaler.fit(X_data)\n",
    "        X_scaled           = scaler.transform(X_data)\n",
    "        X_scaled_df        = pd.DataFrame(X_scaled)\n",
    "        X_data             = X_scaled_df\n",
    "\n",
    "\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                        y_data,\n",
    "                                                        test_size = pct_test,\n",
    "                                                        random_state = seed)\n",
    "\n",
    "\n",
    "    # creating lists for training set accuracy and test set accuracy\n",
    "    training_accuracy = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    \n",
    "    # setting neighbor range\n",
    "    neighbors_settings = range(1, max_neighbors + 1)\n",
    "\n",
    "\n",
    "    for n_neighbors in neighbors_settings:\n",
    "        # building the model based on response variable type\n",
    "        if response_type == 'reg':\n",
    "            clf = KNeighborsRegressor(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "        elif response_type == 'class':\n",
    "            clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "            clf.fit(X_train, y_train)            \n",
    "            \n",
    "        else:\n",
    "            print(\"Error: response_type must be 'reg' or 'class'\")\n",
    "        \n",
    "        \n",
    "        # recording the training set accuracy\n",
    "        training_accuracy.append(clf.score(X_train, y_train))\n",
    "    \n",
    "        # recording the generalization accuracy\n",
    "        test_accuracy.append(clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "    # optionally displaying visualization\n",
    "    if show_viz == True:\n",
    "        # plotting the visualization\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        plt.plot(neighbors_settings, training_accuracy, label = \"training accuracy\")\n",
    "        plt.plot(neighbors_settings, test_accuracy, label = \"test accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"n_neighbors\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    # returning optimal number of neighbors\n",
    "    print(f\"The optimal number of neighbors is: {test_accuracy.index(max(test_accuracy))+1}\")\n",
    "    return test_accuracy.index(max(test_accuracy))+1\n",
    "\n",
    "\n",
    "# determining the optimal number of neighbors\n",
    "opt_neighbors = optimal_neighbors(X_data        = df_meals_norm_data,\n",
    "                                  y_data        = df_meals_norm_target,\n",
    "                                  response_type = 'class')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7245\n",
      "Testing  ACCURACY: 0.7084\n",
      "AUC Score        : 0.6163\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "# FITTING the data\n",
    "scaler.fit(df_meals_norm_data)\n",
    "\n",
    "\n",
    "# TRANSFORMING the data\n",
    "x_scaled     = scaler.transform(df_meals_norm_data)\n",
    "\n",
    "\n",
    "# converting to a DataFrame\n",
    "x_scaled_df  = pd.DataFrame(x_scaled) \n",
    "\n",
    "# train-test split with the scaled data\n",
    "x_train_scaled, x_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
    "            x_scaled_df,\n",
    "            df_meals_norm_target,\n",
    "            random_state = 219,\n",
    "            test_size = 0.25,\n",
    "            stratify = df_meals_norm_target)\n",
    "\n",
    "\n",
    "# INSTANTIATING a KNN classification model with optimal neighbors\n",
    "knn_opt = KNeighborsClassifier(n_neighbors = opt_neighbors)\n",
    "\n",
    "\n",
    "# FITTING the training data\n",
    "knn_fit = knn_opt.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "knn_pred = (knn_fit.predict_proba(x_test_scaled)[:,1]>=0.64).astype(int)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', knn_fit.score(x_train_scaled, y_train_scaled).round(4))\n",
    "print('Testing  ACCURACY:', knn_fit.score(x_test_scaled, y_test_scaled).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4))\n",
    "\n",
    "# saving scoring data\n",
    "knn_train_score = knn_fit.score(x_train_scaled, y_train_scaled).round(4)\n",
    "knn_test_score  = knn_fit.score(x_test_scaled, y_test_scaled).round(4)\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "knn_auc_score   = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = knn_pred).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 1.0\n",
      "Testing  ACCURACY: 0.7043\n",
      "AUC Score        : 0.5808\n",
      "\n",
      "True Negatives : 37\n",
      "False Positives: 119\n",
      "False Negatives: 25\n",
      "True Positives : 306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first random forest model\n",
    "\n",
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning** Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FITTING the training data\n",
    "# rf_default_fit = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred = rf_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "# leaf_space       = pd.np.arange(1, 31, 10)\n",
    "# criterion_space  = ['gini', 'entropy']\n",
    "# bootstrap_space  = [True, False]\n",
    "# warm_start_space = [True, False]\n",
    "# depth_space      = pd.np.arange(1, 8, 1)\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_space,\n",
    "#               'min_samples_leaf' : leaf_space,\n",
    "#               'criterion'        : criterion_space,\n",
    "#               'bootstrap'        : bootstrap_space,\n",
    "#               'warm_start'       : warm_start_space,\n",
    "#               'max_depth'        : depth_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 3,\n",
    "#                                n_iter     = 1000,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning** for Random Forest\n",
    "\n",
    "Tuned Parameters  : {'warm_start': True, 'n_estimators': 350, 'min_samples_leaf': 11, 'max_depth': 7, 'criterion': 'entropy', 'bootstrap': False}\\\n",
    "Tuned Training AUC: 0.5966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7601\n",
      "Forest Tuned Testing  ACCURACY: 0.7659\n",
      "Forest Tuned AUC Score        : 0.6516\n",
      "\n",
      "True Negatives : 52\n",
      "False Positives: 104\n",
      "False Negatives: 10\n",
      "True Positives : 321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=7, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit = forest_tuned.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "forest_tuned_pred = forest_tuned_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                   y_score = forest_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_train_score = forest_tuned.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_test_score  = forest_tuned.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_rf_tn, \\\n",
    "tuned_rf_fp, \\\n",
    "tuned_rf_fn, \\\n",
    "tuned_rf_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_tn}\n",
    "False Positives: {tuned_rf_fp}\n",
    "False Negatives: {tuned_rf_fn}\n",
    "True Positives : {tuned_rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GBM** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.8005\n",
      "Testing ACCURACY : 0.7248\n",
      "AUC Score        : 0.6146\n",
      "\n",
      "True Negatives : 48\n",
      "False Positives: 108\n",
      "False Negatives: 26\n",
      "True Positives : 305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "full_gbm_default = GradientBoostingClassifier(loss          = 'deviance',\n",
    "                                              learning_rate = 0.1,\n",
    "                                              n_estimators  = 100,\n",
    "                                              criterion     = 'friedman_mse',\n",
    "                                              max_depth     = 3,\n",
    "                                              warm_start    = False,\n",
    "                                              random_state  = 219)\n",
    "\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "full_gbm_default_fit = full_gbm_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "full_gbm_default_pred = full_gbm_default_fit.predict(x_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', full_gbm_default_fit.score(x_train, y_train).round(4))\n",
    "print('Testing ACCURACY :', full_gbm_default_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4))\n",
    "\n",
    "# scoring the train and test\n",
    "gbm_train_score = full_gbm_default_fit.score(x_train, y_train).round(4)\n",
    "gbm_test_score = full_gbm_default_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "# scoring the AUC\n",
    "gbm_auc = roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = full_gbm_default_pred).round(4)\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_default_tn, \\\n",
    "gbm_default_fp, \\\n",
    "gbm_default_fn, \\\n",
    "gbm_default_tp = confusion_matrix(y_true = y_test, y_pred = full_gbm_default_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_default_tn}\n",
    "False Positives: {gbm_default_fp}\n",
    "False Negatives: {gbm_default_fn}\n",
    "True Positives : {gbm_default_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameters tuning** for GBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # declaring a hyperparameter space\n",
    "# learn_space        = pd.np.arange(0.1, 2.0, 0.2)\n",
    "# estimator_space    = pd.np.arange(100, 200, 25)\n",
    "# depth_space        = pd.np.arange(1, 8, 2)\n",
    "# warm_start_space   = [True, False]\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'learning_rate' : learn_space,\n",
    "#               'max_depth'     : depth_space,\n",
    "#               'n_estimators'  : estimator_space,\n",
    "#               'warm_start'    : warm_start_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# full_gbm_grid = GradientBoostingClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# full_gbm_cv = RandomizedSearchCV(estimator     = full_gbm_grid,\n",
    "#                            param_distributions = param_grid,\n",
    "#                            cv                  = 3,\n",
    "#                            n_iter              = 500,\n",
    "#                            random_state        = 219,\n",
    "#                            scoring             = make_scorer(roc_auc_score,\n",
    "#                                                  needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# full_gbm_cv.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", full_gbm_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", full_gbm_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 0.7649\n",
      "Testing  ACCURACY: 0.7064\n",
      "AUC Score        : 0.6044\n",
      "\n",
      "True Negatives : 50\n",
      "False Positives: 106\n",
      "False Negatives: 37\n",
      "True Positives : 294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSTANTIATING the model object without hyperparameters\n",
    "\n",
    "# I made several attempts to hyperparameter tuning\n",
    "gbm_tuned = GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.7000000000000001, loss='deviance',\n",
    "                           max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=150,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=219, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=True)\n",
    "\n",
    "# FIT step is needed as we are not using .best_estimator\n",
    "gbm_tuned_fit = gbm_tuned.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "gbm_tuned_pred = gbm_tuned_fit.predict(x_test)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', gbm_tuned_fit.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', gbm_tuned_fit.score(x_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = gbm_tuned_pred).round(4))\n",
    "\n",
    "\n",
    "# scoring the train and test\n",
    "gbm_tuned_train_score = gbm_tuned_fit.score(x_train, y_train).round(4)\n",
    "gbm_tuned_test_score  = gbm_tuned_fit.score(x_test, y_test).round(4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "gbm_tuned_tn, \\\n",
    "gbm_tuned_fp, \\\n",
    "gbm_tuned_fn, \\\n",
    "gbm_tuned_tp = confusion_matrix(y_true = y_test, y_pred = gbm_tuned_pred).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {gbm_tuned_tn}\n",
    "False Positives: {gbm_tuned_fp}\n",
    "False Negatives: {gbm_tuned_fn}\n",
    "True Positives : {gbm_tuned_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** model with a changed alpha treshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ACCURACY: 1.0\n",
      "Testing  ACCURACY: 0.7043\n",
      "AUC Score        : 0.6736\n",
      "\n",
      "True Negatives : 98\n",
      "False Positives: 58\n",
      "False Negatives: 93\n",
      "True Positives : 238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first random forest model\n",
    "\n",
    "# INSTANTIATING a random forest model with default values\n",
    "rf_default_ca = RandomForestClassifier(n_estimators     = 100,\n",
    "                                    criterion        = 'gini',\n",
    "                                    max_depth        = None,\n",
    "                                    min_samples_leaf = 1,\n",
    "                                    bootstrap        = True,\n",
    "                                    warm_start       = False,\n",
    "                                    random_state     = 219)\n",
    "\n",
    "# FITTING the training data\n",
    "rf_default_fit_ca = rf_default_ca.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "rf_default_fit_pred_ca = (rf_default_fit_ca.predict_proba(x_test)[:,1]>=0.65).astype(int)\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', rf_default_fit_ca.score(x_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', rf_default_fit_ca.score(x_test, y_test).round(4))\n",
    "\n",
    "\n",
    "# saving AUC score\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = rf_default_fit_pred_ca).round(4))\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "rf_tn, \\\n",
    "rf_fp, \\\n",
    "rf_fn, \\\n",
    "rf_tp = confusion_matrix(y_true = y_test, y_pred = rf_default_fit_pred_ca).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {rf_tn}\n",
    "False Positives: {rf_fp}\n",
    "False Negatives: {rf_fn}\n",
    "True Positives : {rf_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter tuning** for the Random Forest with changed alpha treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FITTING the training data\n",
    "# rf_default_fit_ca = rf_default.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# # PREDICTING based on the testing set\n",
    "# rf_default_fit_pred_ca = (rf_default_fit_ca.predict_proba(x_test)[:,1]>=0.63).astype(int)\n",
    "\n",
    "\n",
    "# # declaring a hyperparameter space\n",
    "# estimator_space  = pd.np.arange(100, 1100, 250)\n",
    "# leaf_space       = pd.np.arange(1, 31, 10)\n",
    "# criterion_space  = ['gini', 'entropy']\n",
    "# bootstrap_space  = [True, False]\n",
    "# warm_start_space = [True, False]\n",
    "# depth_space      = pd.np.arange(1, 9, 1)\n",
    "\n",
    "# # creating a hyperparameter grid\n",
    "# param_grid = {'n_estimators'     : estimator_space,\n",
    "#               'min_samples_leaf' : leaf_space,\n",
    "#               'criterion'        : criterion_space,\n",
    "#               'bootstrap'        : bootstrap_space,\n",
    "#               'warm_start'       : warm_start_space,\n",
    "#               'max_depth'        : depth_space}\n",
    "\n",
    "\n",
    "# # INSTANTIATING the model object without hyperparameters\n",
    "# forest_grid = RandomForestClassifier(random_state = 219)\n",
    "\n",
    "\n",
    "# # GridSearchCV object\n",
    "# forest_cv = RandomizedSearchCV(estimator           = forest_grid,\n",
    "#                                param_distributions = param_grid,\n",
    "#                                cv         = 3,\n",
    "#                                n_iter     = 1000,\n",
    "#                                scoring    = make_scorer(roc_auc_score,\n",
    "#                                             needs_threshold = False))\n",
    "\n",
    "\n",
    "# # FITTING to the FULL DATASET (due to cross-validation)\n",
    "# forest_cv.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# # PREDICT step is not needed\n",
    "\n",
    "\n",
    "# # printing the optimal parameters and best score\n",
    "# print(\"Tuned Parameters  :\", forest_cv.best_params_)\n",
    "# print(\"Tuned Training AUC:\", forest_cv.best_score_.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result of **Hypeparameter tuning** for Random forest with changed alpha treshold\n",
    "\n",
    "Tuned Parameters  : {'warm_start': True, 'n_estimators': 350, 'min_samples_leaf': 11, 'max_depth': 7, 'criterion': 'entropy', 'bootstrap': False}\\\n",
    "Tuned Training AUC: 0.5966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forest Tuned Training ACCURACY: 0.7601\n",
      "Forest Tuned Testing  ACCURACY: 0.7659\n",
      "Forest Tuned AUC Score        : 0.7735\n",
      "\n",
      "True Negatives : 107\n",
      "False Positives: 49\n",
      "False Negatives: 46\n",
      "True Positives : 285\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# copy/pasting in the best_estimator_ results\n",
    "# to avoid running another RandomizedSearch\n",
    "forest_tuned_ca = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='entropy', max_depth=7, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=11, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=350,\n",
    "                       n_jobs=None, oob_score=False, random_state=219,\n",
    "                       verbose=0, warm_start=True)\n",
    "\n",
    "\n",
    "# FITTING the model object\n",
    "forest_tuned_fit_ca = forest_tuned_ca.fit(df_meals_norm_data, df_meals_norm_target)\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "# The alpha treshpld has been modify to balance between false positives and false negatives\n",
    "\n",
    "forest_tuned_pred_ca = (forest_tuned_fit_ca.predict_proba(x_test)[:,1]>=0.65).astype(int)\n",
    "\n",
    "# SCORING the results\n",
    "print('Forest Tuned Training ACCURACY:', forest_tuned_ca.score(x_train, y_train).round(4))\n",
    "print('Forest Tuned Testing  ACCURACY:', forest_tuned_ca.score(x_test, y_test).round(4))\n",
    "print('Forest Tuned AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                                   y_score = forest_tuned_pred_ca).round(4))\n",
    "\n",
    "\n",
    "# saving scoring data for future use\n",
    "forest_tuned_ca_train_score = forest_tuned_ca.score(x_train, y_train).round(4) # accuracy\n",
    "forest_tuned_ca_test_score  = forest_tuned_ca.score(x_test, y_test).round(4)   # accuracy\n",
    "\n",
    "\n",
    "# saving the AUC score\n",
    "forest_tuned_ca_auc = roc_auc_score(y_true  = y_test,\n",
    "                                 y_score = forest_tuned_pred_ca).round(4) # auc\n",
    "\n",
    "# unpacking the confusion matrix\n",
    "tuned_rf_ca_tn, \\\n",
    "tuned_rf_ca_fp, \\\n",
    "tuned_rf_ca_fn, \\\n",
    "tuned_rf_ca_tp = confusion_matrix(y_true = y_test, y_pred = forest_tuned_pred_ca).ravel()\n",
    "\n",
    "\n",
    "# printing each result one-by-one\n",
    "print(f\"\"\"\n",
    "True Negatives : {tuned_rf_ca_tn}\n",
    "False Positives: {tuned_rf_ca_fp}\n",
    "False Negatives: {tuned_rf_ca_fn}\n",
    "True Positives : {tuned_rf_ca_tp}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=7,\n",
       "                       min_samples_leaf=11, n_estimators=350, random_state=219,\n",
       "                       warm_start=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_tuned_ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                             Confusion Matrix\n",
      "Model           AUC Score      Training Acurracy      Testing Acurracy       TN, FP, FN, TP\n",
      "_____           _________      _________________      ________________       ______________\n",
      "Logistic        0.6246         0.7238                 0.7269                 (53, 103, 30, 301)\n",
      "Tuned logistic  0.6389         0.7313                 0.7372                 (57, 99, 29, 302)\n",
      "Full Tree       0.5414          1.0                    0.5955                  (61, 95, 102, 229)\n",
      "Pruned Tree     0.6217         0.7642                 0.7023                 (62, 94, 51, 280)\n",
      "Tuned Tree      0.6495         0.7437                 0.7515                 (57, 99, 22, 309)\n",
      "KNN             0.6163         0.7245                 0.7084\n",
      "GBM             0.6146         0.8005                 0.7248                 (48, 108, 26, 305)\n",
      "Tuned BGM       0.6044         0.7649                 0.7064                 (50, 106, 37, 294)\n",
      "Tuned R.Forest  0.6516         0.7601                 0.7659                 (52, 104, 10, 321)\n",
      "Tuned R.Forest \n",
      "Changed Alpha   0.7735         0.7601                 0.7659                 (107, 49, 46, 285)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# comparing results and build the table report\n",
    "print(f\"\"\"\n",
    "                                                                             Confusion Matrix\n",
    "Model           AUC Score      Training Acurracy      Testing Acurracy       TN, FP, FN, TP\n",
    "_____           _________      _________________      ________________       ______________\n",
    "Logistic        {logreg_auc_score}         {logreg_train_score}                 {logreg_test_score}         \\\n",
    "        {logreg_tn, logreg_fp, logreg_fn, logreg_tp}\n",
    "Tuned logistic  {lr_tuned_auc}         {lr_tuned_train_score}                 {lr_tuned_test_score}      \\\n",
    "           {lr_tuned_tn, lr_tuned_fp, lr_tuned_fn, lr_tuned_tp}\n",
    "Full Tree       {full_tree_auc_score}          {full_tree_train_score}                    {full_tree_test_score}         \\\n",
    "         {full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp}\n",
    "Pruned Tree     {pruned_tree_auc_score}         {pruned_tree_train_score}                 {pruned_tree_test_score}         \\\n",
    "        {pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp}\n",
    "Tuned Tree      {tree_tuned_auc}         {tree_tuned_train_score}                 {tree_tuned_test_score}      \\\n",
    "           {tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp}\n",
    "KNN             {knn_auc_score}         {knn_train_score}                 {knn_test_score}\n",
    "GBM             {gbm_auc}         {gbm_train_score}                 {gbm_test_score}      \\\n",
    "           {gbm_default_tn, gbm_default_fp, gbm_default_fn, gbm_default_tp}\n",
    "Tuned BGM       {roc_auc_score(y_true  = y_test,y_score = gbm_tuned_pred).round(4)}         \\\n",
    "{gbm_tuned_train_score}                 {gbm_tuned_test_score}      \\\n",
    "           {gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp}\n",
    "Tuned R.Forest  {forest_tuned_auc}         {forest_tuned_train_score}                 {forest_tuned_test_score}      \\\n",
    "           {tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp}\n",
    "Tuned R.Forest \n",
    "Changed Alpha   {forest_tuned_ca_auc}         {forest_tuned_ca_train_score}                 \\\n",
    "{forest_tuned_ca_test_score}                 \\\n",
    "{tuned_rf_ca_tn, tuned_rf_ca_fp, tuned_rf_ca_fn, tuned_rf_ca_tp}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# creating a dictionary for model results\n",
    "model_performance = {\n",
    "    \n",
    "    'Model Name'    : ['Logistic', 'Tuned logistic',  'Full Tree', 'Pruned Tree',\n",
    "                      'Tuned Tree', 'KNN', 'GBM', 'Tuned BGM', 'Tuned R.Forest',\n",
    "                      'Tunden R.Forest Changed Alpha'],\n",
    "           \n",
    "    'AUC Score' : [logreg_auc_score, lr_tuned_auc, full_tree_auc_score, pruned_tree_auc_score,\n",
    "                  tree_tuned_auc, knn_auc_score, gbm_auc, \n",
    "                   roc_auc_score(y_true  = y_test,y_score = gbm_tuned_pred).round(4),\n",
    "                  forest_tuned_auc, forest_tuned_ca_auc],\n",
    "    \n",
    "    'Training Accuracy' : [logreg_train_score, lr_tuned_train_score, \n",
    "                           full_tree_train_score, pruned_tree_train_score, \n",
    "                           tree_tuned_train_score, knn_train_score,\n",
    "                           gbm_train_score, gbm_tuned_train_score,\n",
    "                          forest_tuned_train_score, forest_tuned_ca_train_score],\n",
    "          \n",
    "    'Testing Accuracy'  : [logreg_test_score, lr_tuned_test_score, full_tree_test_score,\n",
    "                           pruned_tree_test_score, tree_tuned_test_score,\n",
    "                          knn_test_score, gbm_test_score, gbm_tuned_test_score,\n",
    "                          forest_tuned_test_score, forest_tuned_ca_test_score],\n",
    "\n",
    "    'Confusion Matrix'  : [(logreg_tn, logreg_fp, logreg_fn, logreg_tp),\n",
    "                           (lr_tuned_tn, lr_tuned_fp, lr_tuned_fn, lr_tuned_tp),\n",
    "                           (full_tree_tn, full_tree_fp, full_tree_fn, full_tree_tp),\n",
    "                           (pruned_tree_tn, pruned_tree_fp, pruned_tree_fn, pruned_tree_tp),\n",
    "                           (tuned_tree_tn, tuned_tree_fp, tuned_tree_fn, tuned_tree_tp),\n",
    "                           ('NaN'),\n",
    "                           (gbm_default_tn, gbm_default_fp, gbm_default_fn, gbm_default_tp),\n",
    "                           (gbm_tuned_tn, gbm_tuned_fp, gbm_tuned_fn, gbm_tuned_tp),\n",
    "                           (tuned_rf_tn, tuned_rf_fp, tuned_rf_fn, tuned_rf_tp),\n",
    "                           (tuned_rf_ca_tn, tuned_rf_ca_fp, tuned_rf_ca_fn, tuned_rf_ca_tp)]}\n",
    "\n",
    "\n",
    "# converting model_performance into a DataFrame\n",
    "model_performance = pd.DataFrame(model_performance)\n",
    "\n",
    "\n",
    "# sending model results to Excel\n",
    "model_performance.to_excel('./model_results/classification_model_performance.xlsx',\n",
    "                           index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chosen model:\n",
    "\n",
    "**Tuned Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Elements of the chosen model:\n",
      "\n",
      "Model:              Tuned Random Forest with changed   \n",
      "                    alpha treshold\n",
      "\n",
      "Item                Value             \n",
      "________________    ______      \n",
      "AUC score:          0.7735\n",
      "Train score:        0.7601\n",
      "Test score:         0.7659\n",
      "Train-Test gap:     -0.01\n",
      "Confusion Matriz:   (107, 49, 46, 285)      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\" Elements of the chosen model:\n",
    "\n",
    "Model:              Tuned Random Forest with changed   \n",
    "                    alpha treshold\n",
    "\n",
    "Item                Value             \n",
    "________________    ______      \n",
    "AUC score:          {forest_tuned_ca_auc}\n",
    "Train score:        {forest_tuned_ca_train_score}\n",
    "Test score:         {forest_tuned_ca_test_score}\n",
    "Train-Test gap:     {round(forest_tuned_ca_train_score - forest_tuned_ca_test_score, 2)}\n",
    "Confusion Matriz:   {tuned_rf_ca_tn, tuned_rf_ca_fp, tuned_rf_ca_fn, tuned_rf_ca_tp}      \n",
    "\"\"\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calling the visual_cm function\n",
    "visual_cm(true_y = y_test,\n",
    "          pred_y = forest_tuned_pred_ca,\n",
    "          labels = ['Reject Promotion', 'Accept Promotion'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.65\n"
     ]
    }
   ],
   "source": [
    "# Print Total Time\n",
    "total =  time.time() - start\n",
    "print(round(total, ndigits = 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
